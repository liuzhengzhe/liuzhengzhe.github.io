<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="shortcut icon" href="myIcon.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="keywords" content="Zhengzhe Liu, The Chinese University of Hong Kong"> 
<meta name="description" content="Zhengzhe Liu's home page">
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Zhengzhe Liu</title>
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-39824124-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
</head>
<body >

<div id="layout-content" style="margin-top:25px">

<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">
					<h1>Zhengzhe Liu &nbsp; <h1>
				</div>
				<h3>PhD candidate</h3>    
				<p><p>
					Dept. of Computer Science and Engineering</br>
					The Chinese University of Hong Kong </br>
					 Hong Kong</br>
					</br>
					Email: <a href="mailto:zzliu@cse.cuhk.edu.hk">zzliu [at] cse.cuhk.edu.hk</a><br>                  
				</p>
			</td>
			<td>
				<img src="2019.jpg" border="0" width="340"></br>
			</td>
		<tr>
	</tbody>
</table>
</table>

<h2>Biography</h2>
<p>
	I am a PhD student in <a href="http://www.cse.cuhk.edu.hk">Computer Science and Engineering Department</a>, <a href="http://www.cuhk.edu.hk">The Chinese University of Hong Kong (CUHK)</a>, supervised by <a href="https://www.cse.cuhk.edu.hk/~cwfu/">Prof. Chi-Wing Fu</a>. 
  Before that, I got MPhil from The Chinese University of Hong Kong and Bachelor from <a href="https://en.sjtu.edu.cn/">Shanghai Jiao Tong University (SJTU)</a>. 
  My research interest includes AI Generated Content (AIGC), Computer Graphics, and 3D Generation. 
</p>


<h2>Experience</h2>
<ul>
	<li>
		<div style="float:left; text-align:left"><a href="https://www.cmu.edu/">Carnegie Mellon University</a>, Pittsburgh, United States</div> <div style="float:right; text-align:right">2024.5~</div><br>
		Incoming Post Doctoral Associate<br>
	</li>
	<li>
		<div style="float:left; text-align:left"><a href="http://research.adobe.com/">Adobe Research</a>, San Jose, United States</div> <div style="float:right; text-align:right">2023.7~2023.10</div><br>
		Research Intern<br>
		Topic: Scene Decomposition and Diffusion Models<br>
	</li>
</ul>

<h2>Selected Publications [<a href="https://scholar.google.com/citations?user=HBpZeWsAAAAJ&hl=en">Google Scholar</a>]</h2>
*: equal contribution, †: corresponding author
   <ul>
     <li>
      <a href="https://arxiv.org/abs/2311.01714">EXIM: A Hybrid Explicit-Implicit Representation for Text-Guided 3D Shape Generation
     </br></a>
      <b>Zhengzhe Liu</b>, Jingyu Hu, Ka-Hei Hui, Xiaojuan Qi, Daniel Cohen-Or, Chi-Wing Fu</br>
      <b>SIGGRAPH Asia (Journal Track)</b>, 2023.</br>
      ACM Transactions on Graphics (<b>TOG</b>), 2023, </br>
      [<a href="https://github.com/liuzhengzhe/EXIM">Code</a>]
      [<a href="https://liuzhengzhe.github.io/EXIM.github.io/">Project page</a>]
      <p style="margin-top:3px"></p>  
      </p>
    </li>  
     <li>
      <a href="https://arxiv.org/pdf/2306.08226.pdf">CLIPXPlore: Coupled CLIP and Shape Spaces for 3D Shape Exploration
     </br></a>
      Jingyu Hu*, Ka-Hei Hui*, <b>Zhengzhe Liu</b>, Hao (Richard) Zhang, Chi-Wing Fu</br>
      <b>SIGGRAPH Asia</b>, 2023.</br>
      <p style="margin-top:3px"></p>  
      </p>
    </li>
     <li>
      <a href="https://cvmi-lab.github.io/Point-UV-Diffusion/paper/point_uv_diffusion.pdf">Texture Generation on 3D Meshes with Point-UV Diffusion
     </br></a>
      Xin Yu, Peng Dai, Wenbo Li, Lan Ma, <b>Zhengzhe Liu†</b>, Xiaojuan Qi† (†: Corresponding author) </br>
      IEEE International Conference on Computer Vision (<b>ICCV</b>) <font color = 'red'>Oral </font>, 2023.</br>
      [<a href="https://cvmi-lab.github.io/Point-UV-Diffusion/">Project page</a>]
      <p style="margin-top:3px"></p>  
      </p>
    </li>
     <li>
      <a href="https://arxiv.org/pdf/2303.15181">DreamStone : Image as Stepping Stone for Text-Guided 3D Shape Generation
     </br></a>
      <b>Zhengzhe Liu</b>, Peng Dai, Ruihui Li, Xiaojuan Qi, Chi-Wing Fu</br>
      IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), 2023.</br>
      [<a href="https://github.com/liuzhengzhe/DreamStone-ISS">Code</a>]
      [<a href="https://liuzhengzhe.github.io/DreamStone.github.io/">Project page</a>]
      <p style="margin-top:3px"></p>  
      </p>
    </li>
    <li>
      <a href="https://arxiv.org/abs/2302.00190">Neural Wavelet-domain Diffusion for 3D Shape Generation, Inversion, and Manipulation
     </br></a>
      Jingyu Hu*, Ka-Hei Hui*, <b>Zhengzhe Liu</b>, Ruihui Li, Chi-Wing Fu</br>
       ACM Transactions on Graphics (<b>TOG</b>), 2023.</br></br>
      <p style="margin-top:3px"></p>  
      </p>
    </li>
     <li>
      <a href="">MGFN++: Magnitude-Contrastive Glance-and-Focus Network for Weakly-Supervised Video Anomaly Detection
     </br></a>
	Yingxian Chen, Weibin Kou, Wilton Fok, <b>Zhengzhe Liu†</b>, Xiaojuan Qi, Yik-Chung Wu† (†: Corresponding author) </br>
      Preprint, 2023.</br>
      <p style="margin-top:3px"></p>  
      </p>
    </li>
  <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Chu_Command-Driven_Articulated_Object_Understanding_and_Manipulation_CVPR_2023_paper.pdf">Command-driven Articulated Object Understanding and Manipulation
   </br></a>
    Ruihang Chu, <b>Zhengzhe Liu</b>, Xiaoqing Ye, Xiao Tan, Xiaojuan Qi, Chi-Wing Fu, Jiaya Jia</br>
    IEEE Conference on Computer Vision and pattern Recognition  (<b>CVPR</b>), 2023.</br>
    [<a href="https://github.com/dvlab-research/Cart">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
     <li>
      <a href="https://arxiv.org/abs/2209.04145">ISS : Image as Stepping Stone for Text-Guided 3D Shape Generation
     </br></a>
      <b>Zhengzhe Liu</b>, Peng Dai, Ruihui Li, Xiaojuan Qi, Chi-Wing Fu</br>
      International Conference on Learning Representations (<b>ICLR</b>) <font color = 'red'>Spotlight </font>, 2023.</br>
      [<a href="https://github.com/liuzhengzhe/DreamStone-ISS">Code</a>]
      <p style="margin-top:3px"></p>  
      </p>
    </li>
  </li>
     <li>
      <a href="https://arxiv.org/abs/2303.14727">You Only Need One Thing One Click: Self-Training for Weakly Supervised 3D Scene Understanding
     </br></a>
      <b>Zhengzhe Liu</b>, Xiaojuan Qi, Chi-Wing Fu</br>
      Preprint, 2023.</br>
      [<a href="https://github.com/liuzhengzhe/One-Thing-One-Click">Code</a>]
      <p style="margin-top:3px"></p>  
      </p>
    </li>
    <li>
      <a href="https://arxiv.org/abs/2211.15098">MGFN : Magnitude-Contrastive Glance-and-Focus Network for Weakly-Supervised Video Anomaly Detection
     </br></a>
      Yingxian Chen, <b>Zhengzhe Liu</b>, Baoheng Zhang, Wilton Fok, Xiaojuan Qi, Yik-Chung Wu</br>
      AAAI Conference on Artificial Intelligence (<b>AAAI</b>) <font color = 'red'>Oral </font>, 2023.</br>
      [<a href="https://github.com/carolchenyx/mgfn">Code</a>]
      <p style="margin-top:3px"></p>  
      </p>
    </li>
    <li>
      <a href="https://arxiv.org/abs/2211.13067">Sparse2Dense: Learning to Densify 3D Features for 3D Object Detection
     </br></a>
      Tianyu Wang, Xiaowei Hu, <b>Zhengzhe Liu</b>, Chi-Wing Fu</br>
      Neural Information Processing Systems (<b>NeurIPS</b>), 2022.</br>
      [<a href="https://github.com/stevewongv/Sparse2Dense">Code</a>]
      <p style="margin-top:3px"></p>  
      </p>
    </li>

  <li>
    <a href="https://arxiv.org/abs/2203.14622">Towards Implicit Text-Guided 3D Shape Generation
   </br></a>
    <b>Zhengzhe Liu</b>, Yi Wang, Xiaojuan Qi, Chi-Wing Fu</br>
    IEEE Conference on Computer Vision and pattern Recognition  (<b>CVPR</b>), 2022.</br>
    [<a href="https://github.com/liuzhengzhe/Towards-Implicit-Text-Guided-Shape-Generation">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

  <li>
    <a href="https://jiaya.me/papers/cvpr22_ruihang.pdf">TWIST: Two-Way Inter-label Self-Training for Semi-supervised 3D Instance Segmentation
   </br></a>
    Ruihang Chu, Xiaoqing Ye, <b>Zhengzhe Liu</b>, Xiao Tan, Xiaojuan Qi, Chi-Wing Fu, Jiaya Jia</br>
    IEEE Conference on Computer Vision and pattern Recognition  (<b>CVPR</b>), 2022.</br>
    [<a href="https://github.com/dvlab-research/TWIST">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

  <li>
    <a href="https://ieeexplore.ieee.org/document/9781811/">MEN: Mutual Enhancement Networks for Sign Language Recognition and Education
   </br></a>
    <b>Zhengzhe Liu</b>, Lei Pang, Xiaojuan Qi.</br>
    IEEE Transactions on Neural Networks and Learning Systems (<b>TNNLS</b>), 2022.</br>
    </p>
  </li>

  <li>
    <a href="https://arxiv.org/pdf/2104.02243.pdf">3D-to-2D Distillation for Indoor Scene Parsing
   </br></a>
    <b>Zhengzhe Liu</b>, Xiaojuan Qi, Chi-Wing Fu</br>
    IEEE Conference on Computer Vision and pattern Recognition  (<b>CVPR</b>),     <font color = 'red'>Oral (4.3% acceptance rate) </font>, 2021.</br>
    [<a href="https://github.com/liuzhengzhe/3D-to-2D-Distillation-for-Indoor-Scene-Parsing">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

    <li>
    <a href="https://arxiv.org/pdf/2104.02246.pdf">One Thing One Click: A Self-Training Approach for Weakly Supervised 3D Semantic Segmentation
   </br></a>
    <b>Zhengzhe Liu</b>, Xiaojuan Qi, Chi-Wing Fu</br>
    IEEE Conference on Computer Vision and pattern Recognition  (<b>CVPR</b>), 2021.</br>
    [<a href="https://github.com/liuzhengzhe/One-Thing-One-Click">Code</a>][<a href=https://youtu.be/98UfbjIwzhs/>Video</a>]    
    <p style="margin-top:3px"></p>  
    </p>
  </li>



    <li>
    <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Liu_Global_Texture_Enhancement_for_Fake_Face_Detection_in_the_Wild_CVPR_2020_paper.pdf">Global Texture Enhancement for Fake Face Detection in the Wild
   </br></a>
    <b>Zhengzhe Liu</b>, Xiaojuan Qi, Philip H.S. Torr.</br>
    IEEE Conference on Computer Vision  and Pattern Recognition (<b>CVPR</b>), 2020.</br>
    [<a href="https://github.com/liuzhengzhe/Global_Texture_Enhancement_for_Fake_Face_Detection_in_the-Wild">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

  <li>
    <a href="https://ieeexplore.ieee.org/abstract/document/9184024">GeoNet++: Iterative Geometric Neural Network with Edge-Aware Refinement for Joint Depth and Surface Normal Estimation
   </br></a>
    Xiaojuan Qi*, <b>Zhengzhe Liu</b>*, Renjie Liao, Philip H. S. Torr, Raquel Urtasun, Jiaya Jia.</br>
    IEEE Transactions on Pattern Analysis and Machine Intelligence  (<b>TPAMI</b>), 2020.</br>
    [<a href="https://github.com/xjqi/GeoNet">Code</a>][<a href="https://hkuhk-my.sharepoint.com/:f:/g/personal/xjqi_hku_hk/Ek0Vm--5oi1GssioLE5LjO0ByLTKpWAG00zYYUCeiydR7g?e=8kAdLZ">Training data</a>]
    <p style="margin-top:3px"></p>
    </p>
  </li>

   <li>
    <a href="https://xjqi.github.io/motiondecomp.pdf">3D Motion Decomposition for RGBD Future Dynamic Scene Synthesis
   </br></a>
    Xiaojuan Qi*, <b>Zhengzhe Liu*</b>, Qifeng Chen, Jiaya Jia.</br>
    IEEE Conference on Computer Vision  and Pattern Recognition (<b>CVPR</b>), 2019.
    <p style="margin-top:3px"></p>  
    </p>
  </li>

  <li>
    <a href="http://delivery.acm.org/10.1145/3250000/3240530/p145-liu.pdf?ip=129.67.95.205&id=3240530&acc=ACTIVE%20SERVICE&key=BF07A2EE685417C5%2EF2FAECDC86A918EB%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&__acm__=1547042293_ce3628fae4da448c78d961f9665d1cef">Self-Boosted Gesture Interactive System with ST-Net</br></a>
    <b> Zhengzhe Liu* </b>, Xiaojuan Qi*, Lei Pang.</br>
    ACM Multimedia Conference (<b>ACM MM</b>), 2018. </br> 
    <p style="margin-top:3px"></p>  
    </p>
  </li>

<li>
<a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Qi_GeoNet_Geometric_Neural_CVPR_2018_paper.pdf">GeoNet: Geometric Neural Network for Joint Depth and Surface Normal Estimation</br></a>
Xiaojuan Qi, Renjie Liao, <b>Zhengzhe Liu</b>, Raquel Urtasun, Jiaya Jia</br>
    IEEE Conference on Computer Vision  and Pattern Recognition(<b>CVPR</b>), 2018.</br>
    [<a href="https://github.com/xjqi/GeoNet">Code</a>][<a href="https://hkuhk-my.sharepoint.com/:f:/g/personal/xjqi_hku_hk/Ek0Vm--5oi1GssioLE5LjO0ByLTKpWAG00zYYUCeiydR7g?e=8kAdLZ">Training data</a>]
<p style="margin-top:3px"></p>
  </li>


  <li>
    <a href="https://link.springer.com/content/pdf/10.1007%2F978-3-319-46484-8_6.pdf">Augmented Feedback in Semantic Segmentation under Image Level Supervision</br></a>
    Xiaojuan Qi, <b>Zhengzhe Liu</b>, Jianping Shi, Jiaya Jia.</br>
    European Conference on Computer Vision (<b>ECCV</b>), 2016. </br>
    <p style="margin-top:3px">
    </p>
  </li>
</ul>


<h2>Honors and Awards</h2>
<ul>
 Microsoft Research Asia (MSRA) Fellowship Nomination Award 2022 (33 in Asia).</br>
 Shanghai Excellent Graduate Award</br>
 Meritorious Winner of MCM (Mathematical Contest in Modeling)</br>
 Excellent Student Scholarship for 3 times, Shanghai Jiao Tong University</br>
 Litian Tangren Scholarship (RMB 10,000)</br>
</ul>

						
<h2>Professional Activities</h2>
<ul>

<li>Conference Review: </li>
 ACM SIGGRAPH Asia 2023.</br>
 International Conference on Computer Vision and Pattern Recognition (CVPR) 2023, 2022, 2021.</br>
 International Conference on Learning Representations (ICLR) 2023.</br>
 Neural Information Processing Systems (NeurIPS) 2023.</br>
 European Conference on Computer Vision (ECCV) 2022.</br>
 International Conference on Computer Vision (ICCV) 2023, 2021.</br>
 Association for the Advancement of Artificial Intelligence (AAAI) 2021.</br>

<li>Journal Review:</li>
IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI).</br>
International Journal of Computer Vision (IJCV).</br>
IEEE Transactions on Neural Networks and Learning Systems (TNNLS).</br>
IEEE Transactions on Image Processing (TIP).</br>
IEEE Transactions on Multimedia (TMM).</br>
IEEE Transactions on Circuits and Systems for Video Technology (TCSVT).</br>
IEEE Transactions on Intelligence Transportation Systems (TITS).</br>
Computers in Biology and Medicine (CIBM).</br>

<li>Invited Talk:</li>
Carnegie Mellon University. Topic: Modeling and Creating the 3D World. 2023.10     </br>
ZhiDongXi (智東西) 以圖為梯——從文字到 3D 形狀生成. 2023.6 [<a href=https://zhidx.com/p/380861.html>Link</a>][<a href=https://apposcmf8kb5033.pc.xiaoe-tech.com/live_pc/l_6479b6f4e4b09d723798e48e>Video</a>]  </br>
AI TIME: ICLR sharing session. 2023.6  [<a href=https://www.youtube.com/watch?v=W9n8Ng2czpQ>Video</a>] </br>
CVPR 2022 Workshop on ScanNet Indoor Scene Understanding Challenge. 2022.6 [<a href=http://www.scan-net.org/cvpr2022workshop/>Link</a>][<a href=https://youtu.be/98UfbjIwzhs/>Video</a>]    </br>

</ul>
<h2>Teaching Assistants</h2>
<table id="Teaching" border="0" width="100%">
<ul>
	<tbody>
		<tr>
			<td>CSCI 3170. Introduction to Database Systems</td>
		</tr>		
		<tr>
			<td>ENGG 2020. Digital Logic and Systems</td>
		</tr>
		<tr>
			<td>CSCI 3180. Principles of Programming Languages</td>
		</tr>
		<tr>
			<td>CSCI 1580. Visual Programming</td>
		</tr>
		<tr>
			<td>ENGG 1100. Engineering and Design</td>
		</tr>
	</tbody>
</table>
</ul>


<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-88615920-1', 'auto');
  ga('send', 'pageview');

</script>

</div>
</body>
</html>
